{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Verify hd-bet works for PET images (try with and without skull)\n",
    "     -> If not look at bet2\n",
    "   \n",
    "3. Try in Native space rather than MNI space\n",
    "   \n",
    "4. Try ADC if available\n",
    "\n",
    "5. Expand Dataset\n",
    "   \n",
    "     -> Check unprocessed data, ADNI data (possibly ADNI for validation later)\n",
    "\n",
    "6. Read literature and try different architectures\n",
    "   \n",
    "    -> Log metrics on test set after each experiment\n",
    "        (SSIM, MSE, Inception score)\n",
    "\n",
    "If use department GPU, make sure don't hog resources (esp if running overnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from monai.networks.nets import AHNet\n",
    "from tqdm import tqdm\n",
    "import monai\n",
    "from monai.utils import progress_bar\n",
    "from monai.config import print_config\n",
    "from monai.data import Dataset, DataLoader, CacheDataset\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    Orientationd,\n",
    "    RandRicianNoised,\n",
    "    RandRotated,\n",
    "    RandFlipd,\n",
    "    Resized,\n",
    "    Rotate90d,\n",
    "    ScaleIntensityd,\n",
    "    DeleteItemsd,\n",
    "    NormalizeIntensityd\n",
    ")\n",
    "from monai.losses.ssim_loss import SSIMLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r dictionary_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. MONAI Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To turn 4D images to 3D (from Ashley's classifier)\n",
    "class MakeSingleVolumed(MapTransform):\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            num_volumes = data[key].shape[0]\n",
    "            data[\"NumVolumes\"] = num_volumes\n",
    "            \n",
    "            if num_volumes != 1:\n",
    "                middle_volume = num_volumes // 2\n",
    "                new_data = np.empty((1,128,128,64))\n",
    "                new_data[0,:,:,:] = data[key][middle_volume,:,:,:]\n",
    "                # fill last slice with the value of num_volumes \n",
    "                new_data[0,:,:,-1] = np.zeros((data[key].shape[1],data[key].shape[2])) + num_volumes\n",
    "                data[key] = torch.from_numpy(new_data)\n",
    "            else:\n",
    "                new_data = np.empty((1,128,128,64))\n",
    "                new_data[0,:,:,:] = data[key][0,:,:,:]\n",
    "                # fill last slice with the value of num_volumes \n",
    "                new_data[0,:,:,-1] = np.zeros((data[key].shape[1],data[key].shape[2])) + num_volumes\n",
    "                data[key] = torch.from_numpy(new_data)\n",
    "                \n",
    "        return data\n",
    "\n",
    "#This uses the mask to scale the intensity of the image (not being used rn)\n",
    "class ScaleImaged(MapTransform):\n",
    "    def __call__(self, data):\n",
    "            data[self.keys[0]] *= (0.4+data[self.keys[1]])\n",
    "\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"], reader=monai.data.ITKReader, image_only=True),\n",
    "        EnsureChannelFirstd(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"]),\n",
    "        Orientationd(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"], axcodes=\"RAS\"),        \n",
    "        EnsureTyped(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"]),\n",
    "        Resized(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"], spatial_size=(128,128,64)),\n",
    "        MakeSingleVolumed(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"]),\n",
    "        Rotate90d(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"]),\n",
    "        RandFlipd(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"], prob=0.5, spatial_axis=1),\n",
    "        RandRotated(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"], prob=0.6, range_z=0.3),\n",
    "        ScaleIntensityd(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"]),\n",
    "        NormalizeIntensityd(keys=[\"t1\", \"t1c\", \"t2\", \"flair\", \"pet\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = dictionary_train[:10]\n",
    "\n",
    "check_ds = Dataset(data=val_files, transform=train_transforms)\n",
    "check_DataLoader = DataLoader(check_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_starts = time()\n",
    "step = 1350\n",
    "slice_index = 32\n",
    "for item in check_DataLoader:\n",
    "    image_datas = item[\"t1\"][0, 0, :, :, slice_index], item[\"t1c\"][0, 0, :, :, slice_index], item[\"t2\"][0, 0, :, :, slice_index], item[\"flair\"][0, 0, :, :, slice_index], item[\"pet\"][0, 0, :, :, slice_index]\n",
    "    \n",
    "    f, axarr = plt.subplots(1, 5)\n",
    "    \n",
    "    axarr[0].imshow(image_datas[0])\n",
    "    axarr[0].set_title(\"T1\")\n",
    "    axarr[1].imshow(image_datas[1])\n",
    "    axarr[1].set_title(\"T1C\")\n",
    "    axarr[2].imshow(image_datas[2])\n",
    "    axarr[2].set_title(\"T2\")\n",
    "    axarr[3].imshow(image_datas[3])\n",
    "    axarr[3].set_title(\"FLAIR\")\n",
    "    axarr[4].imshow(image_datas[4])\n",
    "    axarr[4].set_title(\"PET\")\n",
    "    \n",
    "    step += 1\n",
    "now = time()\n",
    "print(\"It has been {0} seconds since the loop started\".format(now - program_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.cpu_count())\n",
    "\n",
    "train_ds = CacheDataset(data=dictionary_train, transform=train_transforms, cache_num=1024, num_workers=os.cpu_count())\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=os.cpu_count(), drop_last=True)\n",
    "\n",
    "#valid_ds = CacheDataset(data=dictionary_valid, transform=val_transforms, cache_num=1024, num_workers=os.cpu_count())\n",
    "#valid_loader = DataLoader(valid_ds, batch_size=4, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "#test_ds = CacheDataset(data=dictionary_test, transform=val_transforms, cache_num=1024, num_workers=os.cpu_count())\n",
    "#test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLA_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GLA_Generator, self).__init__()\n",
    "        self.ahnet_global = AHNet(spatial_dims=3, in_channels=4, out_channels=16, pretrained=True)\n",
    "\n",
    "        channels = [6, 6, 6]\n",
    "        strides = [1, 1, 1]\n",
    "        \n",
    "        self.ahnet_1 = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=4, out_channels=16, channels=channels, strides=strides)\n",
    "        self.ahnet_2 = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=4, out_channels=16, channels=channels, strides=strides)\n",
    "        self.ahnet_3 = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=4, out_channels=16, channels=channels, strides=strides)\n",
    "        self.ahnet_4 = monai.networks.nets.AttentionUnet(spatial_dims=3, in_channels=4, out_channels=16, channels=channels, strides=strides)\n",
    "\n",
    "        self.conv1 = nn.Conv3d(32, 16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm3d(16)\n",
    "        self.conv2 = nn.Conv3d(16, 1, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm3d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, width, height, depth = x.shape\n",
    "        half_width, half_height = width // 2, height // 2\n",
    "        \n",
    "        # Splitting the input into 4 patches\n",
    "        patch_1 = x[:, :, :half_width, :half_height, :]\n",
    "        patch_2 = x[:, :, :half_width, half_height:, :]\n",
    "        patch_3 = x[:, :, half_width:, :half_height, :]\n",
    "        patch_4 = x[:, :, half_width:, half_height:, :]\n",
    "\n",
    "        x = self.ahnet_global(x)\n",
    "        patch_1 = self.ahnet_1(patch_1)\n",
    "        patch_2 = self.ahnet_2(patch_2)\n",
    "        patch_3 = self.ahnet_3(patch_3)\n",
    "        patch_4 = self.ahnet_4(patch_4)\n",
    "\n",
    "        # Concatenating the processed patches\n",
    "        top_row = torch.cat([patch_1, patch_2], dim=3)  # Concatenate along the height\n",
    "        bottom_row = torch.cat([patch_3, patch_4], dim=3)  # Concatenate along the height\n",
    "        concatenated_patches = torch.cat([top_row, bottom_row], dim=2)  # Concatenate along the width\n",
    "\n",
    "        x = torch.cat([x, concatenated_patches], dim=1)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "gen_net = GLA_Generator()\n",
    "\n",
    "disc_net = monai.networks.nets.Discriminator(\n",
    "    in_shape=(128, 128, 64),\n",
    "    channels=(8, 16, 32, 64, 1),\n",
    "    strides=(2, 2, 2, 2, 1),\n",
    "    num_res_units=1,\n",
    "    kernel_size=3,\n",
    ")\n",
    "\n",
    "# If multiple GPUs are available, run in parallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    gen_net = nn.DataParallel(gen_net)\n",
    "    disc_net = nn.DataParallel(disc_net)\n",
    "\n",
    "gen_net.to(device)\n",
    "disc_net.to(device)\n",
    "\n",
    "real_label = 1\n",
    "gen_label = 0\n",
    "\n",
    "disc_loss = torch.nn.BCELoss()\n",
    "gen_loss = torch.nn.BCELoss()\n",
    "gen_loss2 = SSIMLoss(spatial_dims=3)\n",
    "\n",
    "disc_opt = torch.optim.Adam(disc_net.parameters(), 0.0001)\n",
    "gen_opt = torch.optim.Adam(gen_net.parameters(), 0.0001)\n",
    "\n",
    "def discriminator_loss(gen_images, real_images):\n",
    "    \"\"\"\n",
    "    The discriminator loss if calculated by comparing its\n",
    "    prediction for real and generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    real = real_images.new_full((real_images.shape[0], 1), real_label)\n",
    "    gen = gen_images.new_full((gen_images.shape[0], 1), gen_label)\n",
    "\n",
    "    # Training discriminator to label 1 on real images\n",
    "    realloss = disc_loss(disc_net(real_images), real) \n",
    "\n",
    "    # Training discriminator to label 0 on generated images\n",
    "    genloss = disc_loss(disc_net(gen_images.detach()), gen)\n",
    "\n",
    "    return (realloss + genloss) / 2\n",
    "\n",
    "\n",
    "def generator_loss(input, real_images):\n",
    "    \"\"\"\n",
    "    The generator loss is calculated by determining how well\n",
    "    the discriminator was fooled by the generated images.\n",
    "\n",
    "    \"\"\"\n",
    "    output = disc_net(input[:,0,:,:,:])\n",
    "    cats = output.new_full(output.shape, real_label)\n",
    "    fooling_disc = gen_loss(output, cats)\n",
    "    ssim = gen_loss2(input, real_images)\n",
    "    \n",
    "    # Train generator to fool the discriminator into giving a score of 1, and to have a high SSIM\n",
    "    return fooling_disc + ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_values = [(0, 0)]\n",
    "gen_step_loss = []\n",
    "disc_step_loss = []\n",
    "step = 0\n",
    "max_epochs = 100\n",
    "disc_train_interval = 1\n",
    "disc_train_steps = 4\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    gen_net.train()\n",
    "    disc_net.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        progress_bar(\n",
    "            i,\n",
    "            len(train_loader),\n",
    "            f\"epoch {epoch + 1}, avg loss: {epoch_loss_values[-1][1]:.4f}\",\n",
    "        )\n",
    "        input_images = torch.cat((batch_data[\"t1\"].to(device, dtype=torch.float), \n",
    "                                 batch_data[\"t1c\"].to(device, dtype=torch.float), \n",
    "                                 batch_data[\"t2\"].to(device, dtype=torch.float), \n",
    "                                 batch_data[\"flair\"].to(device, dtype=torch.float)), dim=1).to(device)\n",
    "\n",
    "        real_pet = batch_data[\"pet\"].to(device, dtype=torch.float)\n",
    "        \n",
    "        gen_opt.zero_grad()\n",
    "        gen_images = gen_net(input_images)\n",
    "        loss = generator_loss(gen_images, real_pet)\n",
    "        loss.backward()\n",
    "        gen_opt.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        real_pet = real_pet[:,0,:,:,:]\n",
    "        gen_images = gen_images[:,0,:,:,:]\n",
    "\n",
    "        gen_step_loss.append((step, loss.item()))\n",
    "\n",
    "        if step % disc_train_interval == 0:\n",
    "            disc_total_loss = 0\n",
    "\n",
    "            for _ in range(disc_train_steps):\n",
    "                disc_opt.zero_grad()\n",
    "                dloss = discriminator_loss(gen_images, real_pet)\n",
    "                dloss.backward()\n",
    "                disc_opt.step()\n",
    "                disc_total_loss += dloss.item()\n",
    "\n",
    "            disc_step_loss.append((step, disc_total_loss / disc_train_steps))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append((step, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.semilogy(*zip(*gen_step_loss), label=\"Generator Loss\")\n",
    "plt.semilogy(*zip(*disc_step_loss), label=\"Discriminator Loss\")\n",
    "plt.grid(True, \"both\", \"both\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_starts = time()\n",
    "step = 1350\n",
    "slice_index = 32\n",
    "torch.cuda.empty_cache()\n",
    "gen_net.eval()\n",
    "\n",
    "for item in check_DataLoader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_images = torch.cat((item[\"t1\"].to(device, dtype=torch.float), \n",
    "                                     item[\"t1c\"].to(device, dtype=torch.float), \n",
    "                                     item[\"t2\"].to(device, dtype=torch.float), \n",
    "                                     item[\"flair\"].to(device, dtype=torch.float)), dim=1).to(device)\n",
    "        \n",
    "        image_datas = item[\"t1\"][0, 0, :, :, slice_index], item[\"t1c\"][0, 0, :, :, slice_index], item[\"t2\"][0, 0, :, :, slice_index], item[\"flair\"][0, 0, :, :, slice_index], item[\"pet\"][0, 0, :, :, slice_index], gen_net(input_images)[0, 0, :, :, slice_index] \n",
    "        \n",
    "        f, axarr = plt.subplots(1, 6)\n",
    "        \n",
    "        axarr[0].imshow(image_datas[0])\n",
    "        axarr[0].set_title(\"T1\")\n",
    "        axarr[1].imshow(image_datas[1])\n",
    "        axarr[1].set_title(\"T1C\")\n",
    "        axarr[2].imshow(image_datas[2])\n",
    "        axarr[2].set_title(\"T2\")\n",
    "        axarr[3].imshow(image_datas[3])\n",
    "        axarr[3].set_title(\"FLAIR\")\n",
    "        axarr[4].imshow(image_datas[4])\n",
    "        axarr[4].set_title(\"PET\")\n",
    "        axarr[5].imshow(image_datas[5].cpu())\n",
    "        axarr[5].set_title(\"generated\")\n",
    "        \n",
    "        step += 1\n",
    "\n",
    "\n",
    "now = time()\n",
    "print(\"It has been {0} seconds since the loop started\".format(now - program_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
